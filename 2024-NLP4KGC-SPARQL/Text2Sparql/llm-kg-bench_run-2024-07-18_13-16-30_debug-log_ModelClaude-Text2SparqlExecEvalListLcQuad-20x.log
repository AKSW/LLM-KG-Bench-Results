2024-07-18 13:16:30,752 [DEBUG] config loaded: {'tasks': [{'label': 'Text2SparqlExecEvalListBeastiaryTurtleSubgraph', 'class': 'Text2SparqlExecEvalListBeastiary', 'params': {'kgInfoType': 'subgraph', 'kgInfoFormat': 'turtle'}}, {'label': 'Text2SparqlExecEvalListBeastiaryTurtleSchema', 'class': 'Text2SparqlExecEvalListBeastiary', 'params': {'kgInfoType': 'schema', 'kgInfoFormat': 'turtle'}}, {'label': 'Text2SparqlExecEvalListBeastiaryTurtleSubschema', 'class': 'Text2SparqlExecEvalListBeastiary', 'params': {'kgInfoType': 'subschema', 'kgInfoFormat': 'turtle'}}, {'label': 'Text2SparqlExecEvalListBeastiaryIris', 'class': 'Text2SparqlExecEvalListBeastiary', 'params': {'kgInfoType': 'iris'}}, {'label': 'Text2SparqlExecEvalListLcQuad', 'class': 'Text2SparqlExecEvalListLcQuad', 'params': {}}, {'label': 'Text2SparqlExecEvalListOrganizational', 'class': 'Text2SparqlExecEvalListOrganizational', 'params': {}}, {'label': 'Text2SparqlExecEvalListOrgaNumerical', 'class': 'Text2SparqlExecEvalListOrgaNumerical', 'params': {}}, {'label': 'Text2SparqlExecEvalListSciQA', 'class': 'Text2SparqlExecEvalListSciQA', 'params': {}}, {'label': 'Text2SparqlExecEvalListCoypuMiniTurtleGraph', 'class': 'Text2SparqlExecEvalListCoypuMini', 'params': {'kgInfoType': 'graph', 'kgInfoFormat': 'turtle'}}, {'label': 'Text2SparqlExecEvalListCoypuMiniJsonldGraph', 'class': 'Text2SparqlExecEvalListCoypuMini', 'params': {'kgInfoType': 'graph', 'kgInfoFormat': 'json-ld'}}, {'label': 'Text2SparqlExecEvalListCoypuMiniTurtleMSchema', 'class': 'Text2SparqlExecEvalListCoypuMini', 'params': {'kgInfoType': 'minischema', 'kgInfoFormat': 'turtle'}}, {'label': 'Text2SparqlExecEvalListCoypuMiniJsonldMSchema', 'class': 'Text2SparqlExecEvalListCoypuMini', 'params': {'kgInfoType': 'minischema', 'kgInfoFormat': 'json-ld'}}, {'label': 'Text2SparqlExecEvalListCoypuMiniIris', 'class': 'Text2SparqlExecEvalListCoypuMini', 'params': {'kgInfoType': 'iris'}}, {'label': 'SparqlSyntaxFixingListLcQuad', 'class': 'SparqlSyntaxFixingListLcQuad', 'params': {}}, {'label': 'Text2AnswerListOrgaTurtle', 'class': 'Text2AnswerListOrganizational', 'params': {'graphFormat': 'turtle'}}, {'label': 'Text2AnswerListOrgaJsonld', 'class': 'Text2AnswerListOrganizational', 'params': {'graphFormat': 'json-ld'}}, {'label': 'Sparql2AnswerListOrgaTurtle', 'class': 'Sparql2AnswerListOrganizational', 'params': {'graphFormat': 'turtle'}}, {'label': 'Sparql2AnswerListOrgaJsonld', 'class': 'Sparql2AnswerListOrganizational', 'params': {'graphFormat': 'json-ld'}}], 'models': [{'label': 'Gemini-1.0-Pro', 'class': 'ModelGoogle', 'params': {'model': 'gemini-1.0-pro'}}, {'label': 'Gemini-1.5-Pro', 'class': 'ModelGoogle', 'params': {'model': 'models/gemini-1.5-pro-latest'}}, {'label': 'GPT-3.5t16k_2024-01', 'class': 'ModelGpt', 'params': {'model': 'gpt-3.5-turbo-0125'}}, {'label': 'GPT-4t_2023-11', 'class': 'ModelGpt', 'params': {'model': 'gpt-4-1106-preview'}}, {'label': 'GPT-4t_2024-04', 'class': 'ModelGpt', 'params': {'model': 'gpt-4-turbo-2024-04-09'}}, {'label': 'Claude-2.1', 'class': 'ModelClaude', 'params': {'model': 'claude-2.1'}}, {'label': 'Claude-3-opus', 'class': 'ModelClaude', 'params': {'model': 'claude-3-opus-20240229'}}, {'label': 'Claude-3-sonnet', 'class': 'ModelClaude', 'params': {'model': 'claude-3-sonnet-20240229'}}, {'label': 'Claude-3-haiku', 'class': 'ModelClaude', 'params': {'model': 'claude-3-haiku-20240307'}}], 'sizes': [1000], 'iterations': 20}
2024-07-18 13:16:30,753 [INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListLcQuad']; iterations:20; sizes:[1000]; models:['Claude-2.1', 'Claude-3-opus', 'Claude-3-sonnet', 'Claude-3-haiku']
2024-07-18 13:16:30,753 [DEBUG] trying to get class 'ModelClaude' from module 'LlmKgBench.api.model'
2024-07-18 13:16:30,753 [DEBUG] trying to get class 'ModelClaude' from module 'LlmKgBench.api.model'
2024-07-18 13:16:30,754 [DEBUG] trying to get class 'ModelClaude' from module 'LlmKgBench.api.model'
2024-07-18 13:16:30,754 [DEBUG] trying to get class 'ModelClaude' from module 'LlmKgBench.api.model'
2024-07-18 13:16:30,760 [DEBUG] trying to get class 'Text2SparqlExecEvalListLcQuad' from module 'LlmKgBench.bench.Text2SparqlExecEvalListLcQuad.task'
2024-07-18 13:16:31,150 [DEBUG] task 'Text2SparqlExecEvalListLcQuad' is a BasicLlmKgBenchTask LLM-KG-Task and supports the following parameters: [].
2024-07-18 13:16:31,151 [DEBUG] trying to get class 'Text2SparqlExecEvalListLcQuad' from module 'LlmKgBench.bench.Text2SparqlExecEvalListLcQuad.task'
2024-07-18 13:16:31,205 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:31,240 [INFO] Start for task 'Text2SparqlExecEvalListLcQuad' version '4.0' at 2024-07-18 13:16:31.239953. Task parameter: {}
2024-07-18 13:16:31,240 [DEBUG] init model: class=ModelClaude; params={'model': 'claude-2.1'}.
2024-07-18 13:16:31,240 [DEBUG] trying to get class 'ModelClaude' from module 'LlmKgBench.api.model'
2024-07-18 13:16:31,241 [INFO]   model=Claude-claude-2.1 ...
2024-07-18 13:16:31,241 [INFO]   size=None
2024-07-18 13:16:31,242 [INFO]   iteration=1/20, total=1/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:31,242 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:31.242396; size=None; i=1
2024-07-18 13:16:31,269 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:31,296 [DEBUG]       sending to model "claude-2.1" message(~540 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Somalia in 2009-0-0?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P585,point in time\r\nwd:P1082,population\r\nwd:Q1045,Somalia\r\n"
2024-07-18 13:16:31,297 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:31,298 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:31,339 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': 'Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Somalia in 2009-0-0?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P585,point in time\r\nwd:P1082,population\r\nwd:Q1045,Somalia\r\n'}], 'model': 'claude-2.1'}}
2024-07-18 13:16:31,345 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:31,682 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3e470>
2024-07-18 13:16:31,682 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f98961554c0> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:31,911 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3e440>
2024-07-18 13:16:31,912 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:31,913 [DEBUG] send_request_headers.complete
2024-07-18 13:16:31,913 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:31,914 [DEBUG] send_request_body.complete
2024-07-18 13:16:31,914 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:32,128 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_011imv7Z6teunDuQmaAorbR9'), (b'x-cloud-trace-context', b'169aff634d5760f1c460a20f8bf0c265'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f655e766a50-EWR')])
2024-07-18 13:16:32,129 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:32,130 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:32,130 [DEBUG] receive_response_body.complete
2024-07-18 13:16:32,131 [DEBUG] response_closed.started
2024-07-18 13:16:32,131 [DEBUG] response_closed.complete
2024-07-18 13:16:32,131 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:32,132 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:32,137 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:32,138 [DEBUG] Re-raising status error
2024-07-18 13:16:32,138 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:32.138593; size=None; i=0; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:32,151 [INFO]   iteration=2/20, total=2/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:32,151 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:32.151345; size=None; i=2
2024-07-18 13:16:32,176 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:32,193 [DEBUG]       sending to model "claude-2.1" message(~601 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What is {nominated for} of {Dolores del R\u00edo} that is {for work} is {La Otra} ?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:Q3915489,La Otra\r\nwd:Q124057,Dolores del Rio\r\nwd:P1411,nominated for\r\nwd:P1686,for work\r\n"
2024-07-18 13:16:32,194 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:32,195 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:32,236 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': 'Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What is {nominated for} of {Dolores del RÃ­o} that is {for work} is {La Otra} ?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:Q3915489,La Otra\r\nwd:Q124057,Dolores del Rio\r\nwd:P1411,nominated for\r\nwd:P1686,for work\r\n'}], 'model': 'claude-2.1'}}
2024-07-18 13:16:32,237 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:32,349 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3f1c0>
2024-07-18 13:16:32,349 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9895ffdac0> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:32,587 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3f280>
2024-07-18 13:16:32,588 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:32,589 [DEBUG] send_request_headers.complete
2024-07-18 13:16:32,590 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:32,590 [DEBUG] send_request_body.complete
2024-07-18 13:16:32,591 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:32,766 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_01MNDgU1BHJPbhjvqqy1ktCd'), (b'x-cloud-trace-context', b'b4e215d1b40152994a957ac01ff26459'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f69997fc33a-EWR')])
2024-07-18 13:16:32,767 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:32,768 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:32,768 [DEBUG] receive_response_body.complete
2024-07-18 13:16:32,768 [DEBUG] response_closed.started
2024-07-18 13:16:32,769 [DEBUG] response_closed.complete
2024-07-18 13:16:32,769 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:32,769 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:32,770 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:32,770 [DEBUG] Re-raising status error
2024-07-18 13:16:32,771 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:32.771077; size=None; i=1; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:32,775 [INFO]   iteration=3/20, total=3/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:32,776 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:32.776269; size=None; i=3
2024-07-18 13:16:32,801 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:32,820 [DEBUG]       sending to model "claude-2.1" message(~559 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Clermont-Ferrand on 1-1-2013?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:Q42168,Clermont-Ferrand\r\nwd:P1082,population\r\nwd:P585,point in time\r\n"
2024-07-18 13:16:32,821 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:32,821 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:32,862 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': 'Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Clermont-Ferrand on 1-1-2013?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:Q42168,Clermont-Ferrand\r\nwd:P1082,population\r\nwd:P585,point in time\r\n'}], 'model': 'claude-2.1'}}
2024-07-18 13:16:32,863 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:32,975 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9896011870>
2024-07-18 13:16:32,976 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9896156140> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:33,205 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9896011840>
2024-07-18 13:16:33,205 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:33,206 [DEBUG] send_request_headers.complete
2024-07-18 13:16:33,207 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:33,207 [DEBUG] send_request_body.complete
2024-07-18 13:16:33,208 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:33,379 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_012XmQtMjpCek1noiE7VWUc5'), (b'x-cloud-trace-context', b'b0523a69b364d13fe604d82fcd1028f3'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f6d7ffec3f3-EWR')])
2024-07-18 13:16:33,380 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:33,380 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:33,381 [DEBUG] receive_response_body.complete
2024-07-18 13:16:33,381 [DEBUG] response_closed.started
2024-07-18 13:16:33,381 [DEBUG] response_closed.complete
2024-07-18 13:16:33,382 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:33,382 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:33,382 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:33,383 [DEBUG] Re-raising status error
2024-07-18 13:16:33,383 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:33.383519; size=None; i=2; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:33,388 [INFO]   iteration=4/20, total=4/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:33,388 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:33.388795; size=None; i=4
2024-07-18 13:16:33,418 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:33,435 [DEBUG]       sending to model "claude-2.1" message(~639 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:Who was nominated for the Truman Show at the Academy Awards for Best Supporting Actor?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P1411,nominated for\r\nwd:P2453,nominee\r\nwd:Q214801,The Truman Show\r\nwd:Q106291,Academy Award for Best Supporting Actor\r\n"
2024-07-18 13:16:33,436 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:33,436 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:33,477 [DEBUG] close.started
2024-07-18 13:16:33,478 [DEBUG] close.complete
2024-07-18 13:16:33,481 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': 'Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:Who was nominated for the Truman Show at the Academy Awards for Best Supporting Actor?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P1411,nominated for\r\nwd:P2453,nominee\r\nwd:Q214801,The Truman Show\r\nwd:Q106291,Academy Award for Best Supporting Actor\r\n'}], 'model': 'claude-2.1'}}
2024-07-18 13:16:33,482 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:33,593 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3e020>
2024-07-18 13:16:33,594 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9895ffdb40> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:33,822 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9895f3d990>
2024-07-18 13:16:33,822 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:33,823 [DEBUG] send_request_headers.complete
2024-07-18 13:16:33,823 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:33,824 [DEBUG] send_request_body.complete
2024-07-18 13:16:33,824 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:34,000 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_01Xc65sBJJGomwZJennwHMC7'), (b'x-cloud-trace-context', b'fb899f5ed5148c9a133b2878864bdd4d'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f714e9143ec-EWR')])
2024-07-18 13:16:34,001 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:34,001 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:34,002 [DEBUG] receive_response_body.complete
2024-07-18 13:16:34,003 [DEBUG] response_closed.started
2024-07-18 13:16:34,003 [DEBUG] response_closed.complete
2024-07-18 13:16:34,003 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:34,004 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:34,005 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:34,005 [DEBUG] Re-raising status error
2024-07-18 13:16:34,005 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:34.005871; size=None; i=3; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:34,009 [INFO]   iteration=5/20, total=5/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:34,010 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:34.010629; size=None; i=5
2024-07-18 13:16:34,035 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:34,053 [DEBUG]       sending to model "claude-2.1" message(~553 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What is the cause and place of John Denver's death?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P20,place of death\r\nwd:Q105460,John Denver\r\nwd:P509,cause of death\r\n"
2024-07-18 13:16:34,053 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:34,054 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:34,095 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What is the cause and place of John Denver's death?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P20,place of death\r\nwd:Q105460,John Denver\r\nwd:P509,cause of death\r\n"}], 'model': 'claude-2.1'}}
2024-07-18 13:16:34,096 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:34,208 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9896012ce0>
2024-07-18 13:16:34,209 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9896155dc0> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:34,331 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9896012cb0>
2024-07-18 13:16:34,332 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:34,332 [DEBUG] send_request_headers.complete
2024-07-18 13:16:34,333 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:34,333 [DEBUG] send_request_body.complete
2024-07-18 13:16:34,333 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:34,499 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_01MUjRqTxwDCtfnPYcB5hd1S'), (b'x-cloud-trace-context', b'8c89b1b20e71831e0b2cb9e5fcf6e88d'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f7479654207-EWR')])
2024-07-18 13:16:34,500 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:34,501 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:34,501 [DEBUG] receive_response_body.complete
2024-07-18 13:16:34,501 [DEBUG] response_closed.started
2024-07-18 13:16:34,502 [DEBUG] response_closed.complete
2024-07-18 13:16:34,502 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:34,503 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:34,503 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:34,504 [DEBUG] Re-raising status error
2024-07-18 13:16:34,504 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:34.504880; size=None; i=4; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:34,508 [INFO]   iteration=6/20, total=6/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:34,509 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:34.509653; size=None; i=6
2024-07-18 13:16:34,533 [DEBUG] Popen(['git', 'cat-file', '--batch-check'], cwd=/mnt/d/git/LLM_KG_Bench, stdin=<valid stream>, shell=False, universal_newlines=False)
2024-07-18 13:16:34,551 [DEBUG]       sending to model "claude-2.1" message(~540 chars): "Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Somalia in 2009-0-0?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P585,point in time\r\nwd:P1082,population\r\nwd:Q1045,Somalia\r\n"
2024-07-18 13:16:34,552 [DEBUG] load_ssl_context verify=True cert=None trust_env=True http2=False
2024-07-18 13:16:34,552 [DEBUG] load_verify_locations cafile='/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/certifi/cacert.pem'
2024-07-18 13:16:34,594 [DEBUG] Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': 600, 'files': None, 'json_data': {'max_tokens': 4096, 'messages': [{'role': 'user', 'content': 'Please generate a SPARQL SELECT query for wikidata and the given question. Assume common prefixes like wd or wdt to be defined.\nTo support automated parsing, please answer with just a markdown fenced code block (start and end with ```) containing the sparql query, no other text.\n\nExample for Answer format:\n```sparql\nSELECT ...\n```\n\nQuestion:What was the population of Somalia in 2009-0-0?\n\nHere a csv list mapping IRIs and labels of properties and entities you probably need:\nwd:P585,point in time\r\nwd:P1082,population\r\nwd:Q1045,Somalia\r\n'}], 'model': 'claude-2.1'}}
2024-07-18 13:16:34,596 [DEBUG] close.started
2024-07-18 13:16:34,597 [DEBUG] close.complete
2024-07-18 13:16:34,597 [DEBUG] close.started
2024-07-18 13:16:34,598 [DEBUG] close.complete
2024-07-18 13:16:34,598 [DEBUG] close.started
2024-07-18 13:16:34,598 [DEBUG] close.complete
2024-07-18 13:16:34,600 [DEBUG] close.started
2024-07-18 13:16:34,600 [DEBUG] close.complete
2024-07-18 13:16:34,605 [DEBUG] connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=600 socket_options=None
2024-07-18 13:16:34,722 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f98960131f0>
2024-07-18 13:16:34,723 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9895ffdec0> server_hostname='api.anthropic.com' timeout=600
2024-07-18 13:16:34,843 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f98960135e0>
2024-07-18 13:16:34,844 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2024-07-18 13:16:34,845 [DEBUG] send_request_headers.complete
2024-07-18 13:16:34,846 [DEBUG] send_request_body.started request=<Request [b'POST']>
2024-07-18 13:16:34,847 [DEBUG] send_request_body.complete
2024-07-18 13:16:34,847 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2024-07-18 13:16:35,016 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 18 Jul 2024 11:16:35 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'187'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_01NvXtyuAiyeiEUmmr3dHGrh'), (b'x-cloud-trace-context', b'24993bc3ca3c4a560b70496bbab8a813'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a520f77be65438c-EWR')])
2024-07-18 13:16:35,017 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 400 Bad Request"
2024-07-18 13:16:35,018 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2024-07-18 13:16:35,018 [DEBUG] receive_response_body.complete
2024-07-18 13:16:35,019 [DEBUG] response_closed.started
2024-07-18 13:16:35,019 [DEBUG] response_closed.complete
2024-07-18 13:16:35,020 [DEBUG] HTTP Request: POST https://api.anthropic.com/v1/messages "400 Bad Request"
2024-07-18 13:16:35,020 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 959, in _request
    response.raise_for_status()
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 758, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-18 13:16:35,021 [DEBUG] Not retrying as header `x-should-retry` is set to `false`
2024-07-18 13:16:35,021 [DEBUG] Re-raising status error
2024-07-18 13:16:35,021 [ERROR] exception while evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:35.021899; size=None; i=5; exception=Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 244, in generate_text
    answerObject = self.callChatApi(inputs=inputs, max_length=None) # max_length is not used at the moment, claude takes here a maximum output token count
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 263, in callChatApi
    resp = anthropicModel.messages.create(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/resources/messages.py", line 553, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/anthropic/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits.'}}
2024-07-18 13:16:35,025 [INFO]   iteration=7/20, total=7/80, task=Text2SparqlExecEvalListLcQuad ...
2024-07-18 13:16:35,026 [INFO]     evaluating model=Claude-2.1--Claude-claude-2.1; time=2024-07-18 13:16:35.026110; size=None; i=7
2024-07-18 13:16:35,090 [DEBUG] close.started
2024-07-18 13:16:35,092 [DEBUG] close.complete
