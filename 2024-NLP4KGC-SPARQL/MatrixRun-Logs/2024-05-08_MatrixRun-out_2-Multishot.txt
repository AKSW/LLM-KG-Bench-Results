starting at 2024-05-09T06:40:59+02:00
args: 'ModelGpt' - 'SparqlSyntaxFixingListLcQuad Text2SparqlExecEvalListLcQuad Text2SparqlExecEvalListOrganizational Text2SparqlExecEvalListOrgaNumerical' - '20 10 20' - --config LlmKgBench/configuration-2024-05-sparql.yml
full command LlmKgBench/run-matrix.sh ModelGpt SparqlSyntaxFixingListLcQuad Text2SparqlExecEvalListLcQuad Text2SparqlExecEvalListOrganizational Text2SparqlExecEvalListOrgaNumerical 20 10 20 --config LlmKgBench/configuration-2024-05-sparql.yml
2024-05-09T06:40:59+02:00 starting: ModelGpt-SparqlSyntaxFixingListLcQuad-20x
Do 9. Mai 06:40:59 CEST 2024
[INFO] benchmark configuration set: tasks:['SparqlSyntaxFixingListLcQuad']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'SparqlSyntaxFixingListLcQuad' version '5.0' at 2024-05-09 06:41:01.041131. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:01.086581; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=2/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:08.616281; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=3/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:15.813620; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=4/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:24.463518; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=5/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:31.386342; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=6/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:39.764742; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=7/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:46.598898; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=8/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:41:53.606928; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=9/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:00.417946; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=10/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:07.658254; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=11/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:14.827198; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=12/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:21.723876; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=13/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:29.272445; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=14/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:36.648329; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=15/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:43.595177; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=16/20, total=16/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:50.732279; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=17/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:42:58.262358; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=18/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:43:05.194672; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=19/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:43:12.417449; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=20/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:43:19.255765; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:43:26.444828; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=22/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:43:35.624055; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=23/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:43:47.463004; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=24/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:43:55.702451; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=25/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:04.106204; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=26/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:12.267554; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=27/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:21.767315; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=28/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:30.537622; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=29/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:39.032592; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=30/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:48.102839; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=31/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:44:56.811186; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=32/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:04.816147; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=33/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:13.331919; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=34/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:22.229327; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=35/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:30.069671; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=16/20, total=36/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:38.259013; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=37/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:46.538130; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=38/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:45:54.579255; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=39/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:46:03.357144; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=40/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:46:11.639072; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:46:20.332210; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=42/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:46:28.998590; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=43/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:46:46.390397; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=44/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:46:55.338965; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=45/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:03.718167; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=46/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:12.485791; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=47/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:21.708907; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=48/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:39.455783; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=49/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:48.196801; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=50/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:47:56.963370; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=51/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:06.266855; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=52/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:15.661468; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=53/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:29.107638; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=54/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:38.589336; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=55/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:48.752793; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=16/20, total=56/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:48:56.987327; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=57/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:49:05.273395; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=58/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:49:22.080599; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=59/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:49:30.269669; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=60/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 06:49:39.444442; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 14152, 'GPT-gpt-4-1106-preview': 13392, 'GPT-gpt-4-turbo-2024-04-09': 13987}
[INFO] done, 2024-05-09 06:49:47.671186

real	8m48,605s
user	0m5,839s
sys	0m2,405s
Completed ModelGpt-SparqlSyntaxFixingListLcQuad-20x: Model - 1/1, Task - 1/1, Iteration - 1/1
2024-05-09T06:49:47+02:00 starting: ModelGpt-Text2SparqlExecEvalListLcQuad-20x
Do 9. Mai 06:49:47 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListLcQuad']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListLcQuad' version '3.0' at 2024-05-09 06:49:49.666708. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:49:49.716813; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=2/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:50:04.018461; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=3/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:50:25.533086; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=4/20, total=4/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:50:47.885338; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=5/20, total=5/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:50:55.388919; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=6/20, total=6/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:51:17.354538; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=7/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:51:24.461509; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/20, total=8/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:51:46.531887; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] Backing off _executeSparql(...) for 29.1s (urllib.error.HTTPError: HTTP Error 429: Too Many Requests)
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=9/20, total=9/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:52:38.349181; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=10/20, total=10/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:52:57.249622; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=11/20, total=11/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:53:19.158418; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=12/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:53:26.155665; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=13/20, total=13/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:53:49.135816; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=14/20, total=14/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:54:04.147409; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=15/20, total=15/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:54:58.617826; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=16/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:55:20.227060; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=17/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:55:27.123499; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=18/20, total=18/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:55:52.611656; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=19/20, total=19/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:56:14.755227; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=20/20, total=20/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 06:56:21.868829; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:56:43.401725; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=22/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:56:51.500703; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=23/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:57:25.545324; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=4/20, total=24/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:57:54.402781; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=25/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:58:03.460496; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.7333333333333334, 'f1measure': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0}}
[INFO]   iteration=6/20, total=26/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:58:31.087886; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=27/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:58:39.516790; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/20, total=28/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:59:09.798513; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=29/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:59:34.966087; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=30/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:59:43.360856; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=11/20, total=31/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 06:59:52.595145; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=32/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:00:00.595321; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=13/20, total=33/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:00:34.188692; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=14/20, total=34/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:00:52.519451; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=35/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:01:03.383802; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.7333333333333334, 'f1measure': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0}}
[INFO]   iteration=16/20, total=36/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:01:29.211887; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=37/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:01:37.455034; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=18/20, total=38/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:02:09.388403; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.7333333333333334, 'f1measure': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0}}
[INFO]   iteration=19/20, total=39/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:02:19.026084; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=40/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:02:38.083034; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.7333333333333334, 'f1measure': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:02:56.810187; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=42/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:03:05.870913; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=43/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:03:41.517576; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=44/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:03:50.490914; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=45/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:04:08.844976; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=46/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:04:25.586586; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2285714285714286, 'f1measure': 0.03571428571428572, 'precision': 0.01818181818181818, 'recall': 1.0}}
[INFO]   iteration=7/20, total=47/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:04:34.450627; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 0.0, 'combined': 0.0}}
[INFO]   iteration=8/20, total=48/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:05:03.870767; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=49/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:05:11.657166; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=50/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:05:20.708520; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=51/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:05:35.980559; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=52/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:05:44.273555; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=13/20, total=53/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:06:21.522804; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=54/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:06:30.700737; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=55/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:06:48.503369; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=56/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:07:11.530981; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=57/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:07:20.320904; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=18/20, total=58/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:07:55.632490; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=59/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:08:04.443587; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=60/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:08:23.900068; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 22838, 'GPT-gpt-4-1106-preview': 23574, 'GPT-gpt-4-turbo-2024-04-09': 20757}
[INFO] done, 2024-05-09 07:08:39.136067

real	18m51,475s
user	0m8,143s
sys	0m2,540s
Completed ModelGpt-Text2SparqlExecEvalListLcQuad-20x: Model - 1/1, Task - 2/1, Iteration - 1/1
2024-05-09T07:08:39+02:00 starting: ModelGpt-Text2SparqlExecEvalListOrganizational-20x
Do 9. Mai 07:08:39 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListOrganizational']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListOrganizational' version '3.0' at 2024-05-09 07:08:41.175125. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:41.221454; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=2/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:43.761916; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=3/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:44.517472; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=4/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:45.780635; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=5/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:46.941597; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=6/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:48.283252; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=7/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:49.499556; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/20, total=8/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:52.848648; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=9/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:54.044589; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=10/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:55.253433; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=11/20, total=11/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:56.457809; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=12/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:57.723122; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=13/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:08:58.979473; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=14/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:00.059624; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=15/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:01.074848; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=16/20, total=16/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:02.510461; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=17/20, total=17/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:05.596230; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=18/20, total=18/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:08.906785; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=19/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:09.980290; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=20/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:09:11.189309; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:12.634557; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=22/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:17.365240; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=23/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:23.050777; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=24/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:24.885382; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=25/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:27.391869; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=6/20, total=26/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:30.338007; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=7/20, total=27/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:40.093127; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=28/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:43.892034; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=29/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:47.522659; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=30/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:50.385825; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=31/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:09:52.768640; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=32/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:02.620720; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=33/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:06.251159; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=34/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:08.456261; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=35/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:11.690736; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=36/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:14.375419; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=37/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:18.471270; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=38/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:21.754983; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=39/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:23.436269; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=40/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:10:25.210898; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:28.078720; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=42/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:31.592259; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/20, total=43/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:35.346652; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=44/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:37.152338; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=45/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:39.580412; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=6/20, total=46/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:42.744011; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=7/20, total=47/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:47.348360; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=48/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:48.902944; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=49/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:50.925928; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=50/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:10:55.331871; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=11/20, total=51/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:05.614847; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=12/20, total=52/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:16.594150; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=53/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:20.731409; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=54/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:22.769773; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=15/20, total=55/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:25.891649; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=56/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:29.121187; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=17/20, total=57/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:34.530024; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=58/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:40.500697; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=59/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:43.135157; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=60/60, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:11:45.603539; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 34149, 'GPT-gpt-4-1106-preview': 35522, 'GPT-gpt-4-turbo-2024-04-09': 34785}
[INFO] done, 2024-05-09 07:11:49.541734

real	3m10,406s
user	0m5,556s
sys	0m2,358s
Completed ModelGpt-Text2SparqlExecEvalListOrganizational-20x: Model - 1/1, Task - 3/1, Iteration - 1/1
2024-05-09T07:11:49+02:00 starting: ModelGpt-Text2SparqlExecEvalListOrgaNumerical-20x
Do 9. Mai 07:11:49 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListOrgaNumerical']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListOrgaNumerical' version '3.0' at 2024-05-09 07:11:51.572062. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:11:51.625785; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=2/20, total=2/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:11:57.757845; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=3/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:01.685373; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/20, total=4/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:02.656613; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=5/20, total=5/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:04.212824; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=6/20, total=6/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:05.772991; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=7/20, total=7/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:11.506799; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/20, total=8/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:15.220251; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/20, total=9/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:16.212836; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=10/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:19.238225; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=11/20, total=11/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:20.420399; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=12/20, total=12/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:24.683143; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=13/20, total=13/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:25.646122; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=14/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:26.638301; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=15/20, total=15/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:28.009499; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=16/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:29.212409; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=17/20, total=17/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:32.574678; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=18/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:33.722222; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=19/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:34.686961; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=20/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:12:35.724068; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:37.082038; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/20, total=22/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:39.862742; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=23/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:48.698836; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=4/20, total=24/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:50.352105; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 0.0, 'combined': 0.0}}
[INFO]   iteration=5/20, total=25/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:55.080321; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/20, total=26/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:12:59.628395; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=7/20, total=27/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:07.724216; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/20, total=28/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:14.287276; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=9/20, total=29/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:15.853273; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/20, total=30/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:19.786018; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=31/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:22.247119; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=32/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:25.086102; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=13/20, total=33/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:34.557030; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=14/20, total=34/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:37.105594; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=15/20, total=35/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:47.240364; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=36/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:49.441960; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=37/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:51.650112; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=18/20, total=38/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:55.699206; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=39/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:13:57.265114; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=40/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:14:01.955026; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:04.120181; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {}
[INFO]   iteration=2/20, total=42/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:09.058004; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[ERROR] 'prefix'
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 462, in orchestrateMultishotEvaluation
    scoreI, infoI, nextPrompt, multiShotInfo = self.evaluateAnswerMultiShot(conversation=conversationRest, multiShotInfo=multiShotInfo)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 753, in evaluateAnswerMultiShot
    scores, info, answerParse = self.evaluateAnswerSyntax(answerSparql, scores, info, self.refSparql, self.getDefaultPrefixes())
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 681, in evaluateAnswerSyntax
    answerSparqlIris, _ = getPrefixesAndIrisFromQuery(query_str=answerSparql, prefixesAdd=defaultPrefixes)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in getPrefixesAndIrisFromQuery
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/helper/sparqlHelper.py", line 155, in <dictcomp>
    prefixes = {entry['prefix']:entry['iri'] for (type,entry) in entries if type=='PrefixDecl'}
KeyError: 'prefix'
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/20, total=43/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:16.122076; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=4/20, total=44/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:17.828183; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/20, total=45/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:19.868809; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=6/20, total=46/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:22.626656; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/20, total=47/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:27.268726; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/20, total=48/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:33.494231; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=9/20, total=49/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:35.815620; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=10/20, total=50/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:44.247347; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=11/20, total=51/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:47.857595; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=12/20, total=52/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:14:54.310771; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=13/20, total=53/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:06.295721; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=14/20, total=54/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:10.893724; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=15/20, total=55/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:21.604865; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=16/20, total=56/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:24.450496; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=17/20, total=57/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:30.597437; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=18/20, total=58/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:32.450155; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=19/20, total=59/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:34.441232; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=20/20, total=60/60, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:15:44.044010; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 42676, 'GPT-gpt-4-1106-preview': 42099, 'GPT-gpt-4-turbo-2024-04-09': 41771}
[INFO] done, 2024-05-09 07:15:48.058373

real	3m58,487s
user	0m5,931s
sys	0m2,452s
Completed ModelGpt-Text2SparqlExecEvalListOrgaNumerical-20x: Model - 1/1, Task - 4/1, Iteration - 1/1
2024-05-09T07:15:48+02:00 starting: ModelGpt-SparqlSyntaxFixingListLcQuad-10x
Do 9. Mai 07:15:48 CEST 2024
[INFO] benchmark configuration set: tasks:['SparqlSyntaxFixingListLcQuad']; iterations:10; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'SparqlSyntaxFixingListLcQuad' version '5.0' at 2024-05-09 07:15:50.060683. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=1/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:15:50.107471; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/10, total=2/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:15:57.655202; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/10, total=3/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:04.789445; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/10, total=4/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:11.913963; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/10, total=5/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:19.183038; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/10, total=6/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:26.191560; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/10, total=7/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:33.481910; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/10, total=8/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:40.624484; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/10, total=9/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:49.608237; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/10, total=10/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:16:56.762559; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/10, total=11/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:03.989968; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/10, total=12/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:12.734326; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/10, total=13/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:20.351885; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/10, total=14/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:28.114320; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/10, total=15/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:37.104058; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/10, total=16/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:45.526417; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/10, total=17/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:17:55.534232; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/10, total=18/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:18:04.549054; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/10, total=19/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:18:13.084258; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/10, total=20/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:18:21.403902; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=21/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:18:30.073191; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/10, total=22/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:18:38.143101; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=3/10, total=23/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:18:55.381819; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/10, total=24/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:19:08.975317; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/10, total=25/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:19:17.691650; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=6/10, total=26/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:19:27.454499; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/10, total=27/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:19:36.707427; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=8/10, total=28/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:19:54.060770; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=9/10, total=29/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:20:02.015087; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/10, total=30/30, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:20:10.361154; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 6665, 'GPT-gpt-4-1106-preview': 6727, 'GPT-gpt-4-turbo-2024-04-09': 7097}
[INFO] done, 2024-05-09 07:20:22.163129

real	4m34,077s
user	0m3,846s
sys	0m2,422s
Completed ModelGpt-SparqlSyntaxFixingListLcQuad-10x: Model - 1/1, Task - 1/1, Iteration - 2/1
2024-05-09T07:20:22+02:00 starting: ModelGpt-Text2SparqlExecEvalListLcQuad-10x
Do 9. Mai 07:20:22 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListLcQuad']; iterations:10; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListLcQuad' version '3.0' at 2024-05-09 07:20:24.154171. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=1/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:20:24.205889; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/10, total=2/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:20:31.395596; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/10, total=3/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:20:55.286915; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=4/10, total=4/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:21:10.171625; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=5/10, total=5/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:21:18.128089; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 0.0, 'recall': 0.0}}
[INFO]   iteration=6/10, total=6/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:21:29.627166; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/10, total=7/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:21:36.862467; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/10, total=8/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:21:58.903242; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=9/10, total=9/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:22:20.935727; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=10/10, total=10/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:22:28.697792; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/10, total=11/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:22:49.772319; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=2/10, total=12/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:22:59.381612; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=3/10, total=13/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:23:32.963384; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=4/10, total=14/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:23:41.218172; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=5/10, total=15/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:23:49.699943; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #3
[INFO]     scores (short): {'2': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=6/10, total=16/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:24:14.226387; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     scores (short): {'0': {'answerParse': 1.0, 'combined': 1.0, 'f1measure': 1.0, 'precision': 1.0, 'recall': 1.0}}
[INFO]   iteration=7/10, total=17/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:24:22.455767; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO]     starting next evaluation shot #2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.935824 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.607599 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.221394 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.011678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.869197 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.075501 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.271474 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.610103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.609568 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.150620 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 473, in orchestrateMultishotEvaluation
    answer = model.generate_text(inputs=conversation)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]     scores (short): {'1': {'answerParse': 1.0, 'combined': 0.2, 'f1measure': 0.0, 'precision': 1.0, 'recall': 0.0}}
[INFO]   iteration=8/10, total=18/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:25:43.490443; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.808752 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.542439 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.619426 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.279680 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.942534 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.459320 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.095924 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.010734 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.850974 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.202953 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:26:42.177188; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=19/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:26:42.191516; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.948577 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.699074 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.978686 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.134941 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.893612 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.602776 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.209738 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.521304 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.312274 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.658721 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:27:42.998409; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=20/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:27:43.003143; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.752966 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.943630 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.055093 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.956449 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.814907 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.300732 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.764517 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.082525 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.249176 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.558803 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:28:43.157887; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=21/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:28:43.205496; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.928848 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.773020 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.006317 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.857488 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.148539 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.288768 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.910359 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.828497 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.351699 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.958539 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:29:44.524795; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=22/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:29:44.529217; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.889632 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.992362 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.643255 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.171991 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.513827 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.090280 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.160984 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.189903 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.408565 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.873917 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:30:44.394956; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=23/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:30:44.400204; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.958397 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.687390 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.731921 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.060467 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.894719 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.309202 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.926322 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.396248 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.599109 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.657629 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:31:48.670614; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=24/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:31:48.677122; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.911174 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.695915 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.381769 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.466475 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.531324 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.715966 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.315187 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.839689 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.328231 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.983604 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:32:48.782057; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=25/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:32:48.786539; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.845419 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.755814 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.040819 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.863132 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.920965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.076470 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.324670 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.238267 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.355313 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.846060 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:33:47.082194; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=26/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:33:47.086414; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.848524 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.917500 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.473031 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.821753 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.490602 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.493475 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.067432 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.767480 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.875006 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.045164 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:34:46.532293; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=27/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:34:46.537914; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.879984 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.793609 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.978101 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.194013 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.502567 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.404234 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.317727 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.500658 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.677167 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.750674 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:35:46.366002; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=28/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:35:46.373857; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.835587 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.939326 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.854250 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.516665 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.683943 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.961393 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.332169 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.194561 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.676314 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.176202 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:36:46.414949; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=29/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:36:46.419847; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.901422 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.672212 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.471989 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.559011 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.980872 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.463281 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.892854 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.309636 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.658446 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.393852 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:37:48.447962; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=30/30, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:37:48.452479; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.980702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.713855 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.943118 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.105437 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.270938 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.977730 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.281530 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.015179 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.703124 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.648626 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:38:48.959575; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO] Total bytes transfered(in+out) per model: {'GPT-gpt-3.5-turbo-0125': 10383, 'GPT-gpt-4-1106-preview': 7786}
[INFO] done, 2024-05-09 07:38:48.967018

real	18m26,790s
user	0m5,285s
sys	0m2,474s
Completed ModelGpt-Text2SparqlExecEvalListLcQuad-10x: Model - 1/1, Task - 2/1, Iteration - 2/1
2024-05-09T07:38:49+02:00 starting: ModelGpt-Text2SparqlExecEvalListOrganizational-10x
Do 9. Mai 07:38:49 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListOrganizational']; iterations:10; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListOrganizational' version '3.0' at 2024-05-09 07:38:50.982669. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=1/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:38:51.029041; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.963372 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.632248 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.387398 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.929672 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.822444 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.083324 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.214216 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.614120 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.200130 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.155686 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:39:50.321569; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=2/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:39:50.331964; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.805873 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.989872 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.493743 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.923567 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.502001 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.025847 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.388017 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.253296 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.726748 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.391873 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:40:49.729702; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=3/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:40:49.735226; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.947160 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.701158 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.895913 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.275106 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.591516 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.423720 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.981391 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.300553 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.766422 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.144043 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:41:49.599912; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=4/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:41:49.606357; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.930163 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.950707 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.242274 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.284112 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.037930 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.914748 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.540879 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.738567 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.787129 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.706499 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:42:50.804325; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=5/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:42:50.809241; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.866573 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.963703 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.656629 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.017589 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.671159 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.549992 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.220092 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.874527 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.188765 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.675956 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:43:52.284955; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=6/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:43:52.288300; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.996033 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.783531 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.136082 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.071276 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.200862 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.696780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.223635 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.090229 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.331298 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.280056 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:44:51.002000; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=7/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:44:51.010775; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.932770 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.599300 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.394053 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.907055 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.706289 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.283830 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.476315 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.503684 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.120864 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.304507 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:45:48.792051; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=8/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:45:48.796642; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.942036 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.755457 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.199954 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.547401 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.998395 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.145825 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.510175 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.327965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.720839 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.795678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:46:49.759796; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=9/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:46:49.764154; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.843241 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.814134 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.067310 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.749403 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.454860 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.137150 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.760279 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.437740 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.831861 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.219250 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:47:48.192357; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=10/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:47:48.198540; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.771563 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.854024 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.757332 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.501595 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.259987 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.757856 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.252739 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.996384 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.308054 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.668118 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 07:48:49.310225; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/10, total=11/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:48:49.358884; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.856911 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.732837 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.185099 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.288977 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.212965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.158664 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.263969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.576654 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.546557 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.571677 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:49:48.058588; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=12/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:49:48.062656; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.946638 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.876910 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.476154 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.704880 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.038360 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.306121 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.705292 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.132588 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.832075 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.747376 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:50:48.789799; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=13/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:50:48.794191; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.848200 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.939999 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.686122 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.509673 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.461122 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.924772 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.479167 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.766514 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.948448 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.399427 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:51:49.619064; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=14/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:51:49.624738; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.969698 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.738444 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.483851 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.327116 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.836897 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.209724 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.840325 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.503318 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.246228 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.790771 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:52:49.425576; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=15/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:52:49.430074; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.814978 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.774767 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.047353 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.222606 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.867449 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.513890 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.098252 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.856801 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.936817 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.626773 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:53:48.093825; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=16/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:53:48.098027; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.815201 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.755128 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.839758 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.344612 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.917286 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.969500 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.301912 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.111432 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.450161 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.709796 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:54:49.198805; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=17/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:54:49.203471; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.799661 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.587922 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.289012 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.811140 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.109211 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.652942 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.392418 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.445826 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.999730 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.279611 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:55:48.532623; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=18/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:55:48.537459; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.942822 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.545655 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.373215 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.458474 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.733278 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.547483 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.387233 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.567383 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.095684 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.641627 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:56:45.676497; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=19/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:56:45.680295; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.767736 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.631578 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.221931 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.745762 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.536341 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.551956 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.077231 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.186220 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.876940 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.128728 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:57:45.263796; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=20/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:57:45.268573; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.960207 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.686753 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.134125 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.962541 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.860578 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.295756 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.573492 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.955576 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.716720 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.365756 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 07:58:45.754268; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=21/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:58:45.800495; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.915163 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.628152 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.139334 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.730273 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.944170 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.374682 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.443176 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.454476 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.639523 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.672650 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:59:48.017787; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=22/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 07:59:48.023127; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.828981 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.655519 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.250633 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.515043 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.980919 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.966490 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.213800 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.375361 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.378752 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.412561 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:00:44.782135; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=23/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:00:44.786697; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.967305 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.624592 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.947420 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.406299 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.237295 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.710377 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.232122 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.750641 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.008170 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.262702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:01:44.801064; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=24/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:01:44.805158; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.918852 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.742781 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.252380 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.982016 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.243283 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.453976 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.064148 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.981009 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.795409 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.431125 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:02:46.630684; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=25/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:02:46.635845; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.792960 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.683909 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.357784 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.142489 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.371624 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.321706 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.251698 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.760466 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.498155 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.168038 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:03:48.034972; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=26/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:03:48.039188; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.782181 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.759552 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.598770 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.477580 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.098741 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.663496 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.461755 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.892039 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.846300 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.778151 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:04:48.221193; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=27/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:04:48.226211; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.822663 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.942979 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.571490 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.168610 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.657636 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.520011 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.158416 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.467603 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.241121 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.220141 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:05:46.840909; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=28/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:05:46.845142; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.918902 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.540393 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.371201 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.432520 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.292400 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.214362 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.011154 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.916314 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.244425 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.088329 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:06:47.709355; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=29/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:06:47.712888; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.884332 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.578432 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.078236 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.795202 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.931795 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.313054 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.201041 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.412746 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.562069 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.811800 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:07:48.224565; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=30/30, task=Text2SparqlExecEvalListOrganizational ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:07:48.229576; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.774051 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.937304 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.424727 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.336290 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.631557 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.238562 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.448638 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.530501 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.443281 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.236061 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:08:46.031969; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO] Total bytes transfered(in+out) per model: {}
[INFO] done, 2024-05-09 08:08:46.035728

real	29m57,035s
user	0m5,306s
sys	0m2,672s
Completed ModelGpt-Text2SparqlExecEvalListOrganizational-10x: Model - 1/1, Task - 3/1, Iteration - 2/1
2024-05-09T08:08:46+02:00 starting: ModelGpt-Text2SparqlExecEvalListOrgaNumerical-10x
Do 9. Mai 08:08:46 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListOrgaNumerical']; iterations:10; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListOrgaNumerical' version '3.0' at 2024-05-09 08:08:47.996869. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=1/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:08:48.042792; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.849165 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.726373 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.490155 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.640353 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.229166 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.377525 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.647977 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.886777 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.257430 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.753223 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:09:48.293471; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=2/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:09:48.306069; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.866154 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.903759 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.215781 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.589253 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.429503 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.899501 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.055316 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.987697 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.410782 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.401266 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:10:46.924335; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=3/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:10:46.927873; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.833057 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.725507 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.687716 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.654897 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.158466 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.007743 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.270036 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.969411 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.889220 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.199721 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:11:47.168777; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=4/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:11:47.173141; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.751894 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.604958 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.375845 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.801075 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.068883 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.484501 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.921692 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.486681 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.341342 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.099487 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:12:47.967170; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=5/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:12:47.973004; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.951182 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.986331 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.694444 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.711540 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.668116 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.394318 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.372487 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.994606 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.135357 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.779341 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:13:50.426541; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=6/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:13:50.429957; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.782412 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.985335 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.887282 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.624348 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.960045 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.303483 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.583281 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.931070 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.930349 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.545169 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:14:51.916731; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=7/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:14:51.921685; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.836156 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.959417 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.628325 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.073520 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.940033 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.238983 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.410773 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.070512 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.956286 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.020717 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:15:49.126760; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=8/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:15:49.131332; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.846391 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.869227 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.152561 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.146866 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.789789 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.389246 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.009465 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.551604 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.856447 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.622682 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:16:48.319917; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=9/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:16:48.325625; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.958216 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.957781 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.723659 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.957736 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.002678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.554635 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.078850 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.074236 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.088145 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.248442 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:17:45.952184; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=10/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:17:45.957803; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.936614 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.767804 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.771399 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.068957 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.258357 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.002520 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.760842 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.250767 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.392619 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.233015 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:18:44.871260; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/10, total=11/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:18:44.918120; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.834502 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.739254 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.091620 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.028678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.776437 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.347280 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.452085 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.369825 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.218878 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.583862 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:19:45.630579; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=12/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:19:45.634600; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.916638 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.842770 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.650757 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.855750 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.424993 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.903834 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.278519 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.734879 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.272733 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.469205 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:20:44.839863; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=13/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:20:44.843642; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.967079 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.627142 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.161012 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.146098 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.124481 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.885221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.790025 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.381233 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.271447 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.976786 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:21:43.145326; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=14/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:21:43.151667; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.910953 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.986636 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.530530 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.848366 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.610022 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.683664 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.761969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.097264 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.397856 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.675001 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:22:44.505484; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=15/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:22:44.510363; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.866125 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.802318 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.636543 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.756634 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.751541 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.307701 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.693821 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.642808 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.320708 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.576508 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:23:44.756369; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=16/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:23:44.761524; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.800173 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.911132 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.461323 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.443596 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.087883 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.088549 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.626198 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.349259 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.051857 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.735089 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:24:44.951481; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=17/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:24:44.955500; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.781291 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.802940 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.944622 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.750889 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.350702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.988202 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.331092 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.826766 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.847935 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.138453 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:25:43.536002; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=18/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:25:43.539473; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.939054 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.654211 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.172732 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.999632 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.418719 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.379156 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.213578 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.858518 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.092886 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.054945 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:26:44.116910; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=19/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:26:44.121158; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.877823 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.791420 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.511658 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.471050 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.863652 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.568754 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.440382 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.764484 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.734175 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.293840 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:27:46.199420; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=20/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:27:46.202952; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.810068 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.727551 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.064845 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.401565 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.010821 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.930549 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.243046 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.868823 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.047532 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.312926 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:28:45.580121; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/10, total=21/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:28:45.626278; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.866303 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.612287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.351319 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.069462 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.325819 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.406122 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.900842 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.425890 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.992190 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.449777 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:29:46.355609; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/10, total=22/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:29:46.361007; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.984287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.867892 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.499604 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.092682 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.133089 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.178905 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.333442 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.846084 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.953808 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.621664 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:30:46.761142; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/10, total=23/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:30:46.766923; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.818752 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.848043 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.737609 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.508188 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.262969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.632310 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.703977 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.823385 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.795447 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.995677 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:31:48.947147; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/10, total=24/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:31:48.951198; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.909081 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.975780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.728877 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.315623 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.136226 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.973592 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.259520 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.551651 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.373696 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.280878 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:32:50.454576; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/10, total=25/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:32:50.458179; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.926950 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.732814 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.772482 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.008740 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.619568 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.923856 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.836621 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.774966 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.008105 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.283522 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:33:52.312786; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/10, total=26/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:33:52.316727; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.957137 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.864231 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.663700 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.896633 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.292412 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.800117 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.959958 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.717541 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.994082 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.785388 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:34:54.214074; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/10, total=27/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:34:54.217844; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.842152 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.731685 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.406745 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.804163 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.268707 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.885901 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.707513 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.286070 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.773271 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.727628 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:35:56.693839; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/10, total=28/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:35:56.698396; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.773086 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.715588 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.134090 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.299937 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.739998 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.273699 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.497232 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.694373 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.433898 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.135946 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:36:57.354693; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/10, total=29/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:36:57.358643; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.779390 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.983380 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.385323 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.959537 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.991173 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.640887 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.769397 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.179451 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.562235 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.986744 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:37:58.260024; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/10, total=30/30, task=Text2SparqlExecEvalListOrgaNumerical ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:37:58.263560; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.760627 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.826508 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.131103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.173700 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.103722 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.418210 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.586716 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.572605 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.852482 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.201287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 08:38:57.747407; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO] Total bytes transfered(in+out) per model: {}
[INFO] done, 2024-05-09 08:38:57.751055

real	30m11,705s
user	0m5,208s
sys	0m2,718s
Completed ModelGpt-Text2SparqlExecEvalListOrgaNumerical-10x: Model - 1/1, Task - 4/1, Iteration - 2/1
2024-05-09T08:38:58+02:00 starting: ModelGpt-SparqlSyntaxFixingListLcQuad-20x
Do 9. Mai 08:38:58 CEST 2024
[INFO] benchmark configuration set: tasks:['SparqlSyntaxFixingListLcQuad']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'SparqlSyntaxFixingListLcQuad' version '5.0' at 2024-05-09 08:38:59.711364. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:38:59.756463; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.917793 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.828768 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.169396 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.745481 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.586121 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.100630 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.717776 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.431189 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.976711 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.875934 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:40:01.174689; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=2/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:40:01.185582; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.755438 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.985508 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.086442 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.886942 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.468196 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.324405 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.864221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.801262 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.784039 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.234094 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:41:02.418564; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=3/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:41:02.424379; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.916790 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.673071 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.802291 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.078262 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.441906 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.044787 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.521797 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.831887 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.809087 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.724094 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:42:04.328389; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=4/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:42:04.335102; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.762287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.702771 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.215868 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.531825 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.520809 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.322740 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.892715 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.793408 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.620361 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.788404 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:43:08.498661; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=5/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:43:08.504061; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.982361 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.925947 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.153193 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.692196 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.250532 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.678088 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.441751 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.325392 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.347841 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.664895 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:44:06.920508; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=6/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:44:06.925306; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.878184 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.557919 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.056912 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.046591 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.580323 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.368287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.858818 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.773691 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.760472 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.659186 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:45:07.283673; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=7/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:45:07.288633; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.882030 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.736021 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.380116 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.022518 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.964472 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.292625 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.461094 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.717487 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.980865 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.719450 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:46:07.475711; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=8/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:46:07.480692; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.988462 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.517678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.927171 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.625172 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.256875 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.015770 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.643668 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.025625 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.139194 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.710263 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:47:06.241171; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=9/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:47:06.245278; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.908410 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.953677 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.492519 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.479185 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.355269 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.413224 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.596740 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.730812 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.409211 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.127151 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:48:03.683309; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=10/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:48:03.688773; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.898071 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.767959 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.025843 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.889575 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.412955 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.182934 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.262850 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.366315 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.066031 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.506793 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:49:01.793469; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=11/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:49:01.797291; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.811592 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.780408 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.665028 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.089360 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.592694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.081621 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.013614 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.962087 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.863048 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.826974 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:50:02.227309; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=12/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:50:02.230752; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.969508 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.574599 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.162596 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.801489 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.726053 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.567411 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.815667 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.808845 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.691714 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.949376 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:51:05.321019; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=13/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:51:05.325569; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.969694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.568528 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.733440 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.585309 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.847393 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.506709 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.600643 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.393111 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.071170 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.549234 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:52:07.216851; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=14/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:52:07.221871; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.914589 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.601689 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.668159 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.664792 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.715298 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.589629 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.927938 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.167491 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.825233 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.565827 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:53:08.737413; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=15/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:53:08.741737; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.837175 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.535932 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.071858 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.726504 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.524413 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.505428 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.299731 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.728778 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.447321 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.128029 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:54:06.417324; size=None; i=14; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=16/20, total=16/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:54:06.422118; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.796366 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.619007 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.130717 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.436442 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.665277 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.982286 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.629674 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.057025 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.051375 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.024846 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:55:03.759175; size=None; i=15; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=17/20, total=17/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:55:03.762588; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.934153 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.963540 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.434066 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.885718 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.123172 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.489165 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.308823 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.658461 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.724053 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.052463 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:56:04.188631; size=None; i=16; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=18/20, total=18/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:56:04.192931; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.938118 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.849607 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.343954 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.397450 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.063478 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.149093 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.124595 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.982755 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.715509 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.485933 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:57:01.140400; size=None; i=17; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=19/20, total=19/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:57:01.145105; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.763385 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.798565 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.938314 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.631937 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.532544 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.859605 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.302477 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.385594 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.127243 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.394313 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:58:01.009762; size=None; i=18; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=20/20, total=20/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:58:01.013877; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.963672 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.712909 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.363999 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.364845 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.835563 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.368349 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.826715 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.781857 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.522222 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.336468 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 08:59:02.035184; size=None; i=19; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 08:59:02.082141; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.800106 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.822213 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.656947 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.210506 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.419938 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.263500 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.219318 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.335140 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.642720 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.495860 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:00:01.291200; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=22/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:00:01.295717; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.988249 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.589894 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.057002 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.446895 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.081683 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.194020 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.637923 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.622007 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.051258 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.762572 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:00:59.636269; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=23/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:00:59.641178; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.864465 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.629948 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.246936 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.687156 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.364670 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.454350 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.727671 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.853308 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.568780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.434320 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:01:59.101960; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=24/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:01:59.106791; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.791830 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.628435 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.165460 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.003414 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.143187 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.925394 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.012951 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.303883 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.486387 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.922015 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:02:58.357272; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=25/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:02:58.360720; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.992435 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.965979 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.720151 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.106354 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.124621 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.733034 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.146864 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.017223 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.041460 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.078223 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:03:57.187505; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=26/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:03:57.191138; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.978598 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.837429 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.482861 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.986719 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.012146 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.182847 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.440206 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.507722 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.564467 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.924932 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:04:55.947140; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=27/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:04:55.951647; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.765992 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.873942 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.719653 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.045057 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.714654 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.538038 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.951493 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.522209 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.076670 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.637113 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:05:56.608478; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=28/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:05:56.613087; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.984947 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.797972 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.884694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.882794 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.829231 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.294596 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.286398 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.503172 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.476764 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.342130 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:06:56.743080; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=29/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:06:56.748470; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.855000 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.620359 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.613688 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.530205 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.175744 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.629405 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.141586 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.490113 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.545525 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.822106 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:07:56.121793; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=30/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:07:56.126426; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.751547 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.849970 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.074622 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.772844 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.640073 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.497982 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.636672 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.876132 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.127421 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.002630 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:08:55.516722; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=31/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:08:55.520649; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.795763 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.796004 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.526942 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.385965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.115758 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.205907 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.928287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.642103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.664883 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.284776 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:09:53.771611; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=32/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:09:53.775998; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.818667 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.704562 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.089749 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.303380 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.727886 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.329920 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.800981 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.363406 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.721221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.719224 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:10:53.166675; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=33/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:10:53.172997; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.757088 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.722991 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.955953 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.430285 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.465447 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.518500 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.576438 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.612190 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.389428 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.296363 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:11:52.715165; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=34/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:11:52.720945; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.809954 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.985571 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.728649 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.620370 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.128862 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.674128 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.734088 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.616773 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.881892 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.695563 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:12:55.600033; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=35/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:12:55.604558; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.766911 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.539804 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.391155 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.818540 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.730725 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.050483 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.242982 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.920046 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.586302 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.400950 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:13:55.763314; size=None; i=14; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=16/20, total=36/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:13:55.768090; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.916958 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.838089 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.252504 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.085034 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.588696 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.881792 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.670047 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.659907 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.778988 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.263016 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:14:56.673214; size=None; i=15; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=17/20, total=37/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:14:56.678702; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.881476 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.922624 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.966390 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.066243 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.452014 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.029379 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.647959 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.915607 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.548976 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.086553 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:15:56.058422; size=None; i=16; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=18/20, total=38/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:15:56.063085; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.838119 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.850959 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.349256 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.675993 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.043703 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.911802 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.572355 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.933308 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.990571 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.986014 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:16:56.009271; size=None; i=17; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=19/20, total=39/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:16:56.015185; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.849459 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.557204 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.418244 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.598276 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.186587 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.920819 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.462695 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.426322 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.631451 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.860737 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:17:57.668855; size=None; i=18; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=20/20, total=40/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:17:57.673209; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.770156 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.505101 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.575457 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.874543 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.705916 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.227708 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.567233 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.372346 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.709562 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.021181 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:18:59.768348; size=None; i=19; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:18:59.815205; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.984240 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.583635 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.216915 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.328589 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.676191 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.130733 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.034879 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.855757 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.969823 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.771370 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:19:59.536224; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=42/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:19:59.540356; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.903845 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.993930 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.914351 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.050188 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.054295 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.675702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.066969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.061931 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.381361 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.064197 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:20:58.859357; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=43/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:20:58.864876; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.919161 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.616241 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.094704 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.367422 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.147418 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.247671 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.527572 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.432231 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.790312 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.746659 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:21:57.595482; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=44/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:21:57.600742; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.806114 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.504287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.326354 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.271983 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.019780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.962627 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.423946 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.226024 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.088861 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.877115 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:22:57.829764; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=45/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:22:57.834687; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.885579 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.849772 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.528269 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.140781 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.450476 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.528383 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.924528 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.471910 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.518285 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.485964 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:23:59.419730; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=46/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:23:59.424898; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.853852 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.779809 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.641041 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.218095 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.596344 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.483498 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.233717 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.824983 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.228004 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.127808 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:24:57.042784; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=47/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:24:57.048901; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.825807 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.690233 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.441040 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.475179 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.596342 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.179579 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.958887 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.509662 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.899936 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.537516 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:25:56.062196; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=48/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:25:56.065802; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.953905 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.768691 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.171006 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.287999 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.515017 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.685732 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.481717 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.734705 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.026734 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.431384 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:26:55.755648; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=49/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:26:55.760031; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.820328 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.838419 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.308814 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.817133 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.021186 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.582658 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.383067 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.843458 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.378449 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.576679 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:27:55.299915; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=50/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:27:55.305192; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.948356 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.931255 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.911522 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.946665 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.956748 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.255854 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.509991 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.715625 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.526291 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.096726 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:28:58.056287; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=51/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:28:58.061523; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.782654 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.886511 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.708766 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.986252 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.237183 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.978405 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.869475 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.104522 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.940661 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.892337 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:29:59.409460; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=52/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:29:59.413386; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.752988 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.776221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.131267 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.389973 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.867836 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.360696 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.506620 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.748798 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.927876 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.047647 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:30:59.750353; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=53/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:30:59.754282; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.751813 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.921242 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.740911 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.094237 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.478667 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.861160 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.477410 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.403393 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.796780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.331471 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:31:59.606626; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=54/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:31:59.610300; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.787614 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.569516 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.995050 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.949299 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.459633 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.887086 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.705847 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.824463 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.420622 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.472338 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:33:00.541586; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=55/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:33:00.548237; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.913769 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.820245 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.284858 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.478694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.054107 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.359205 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.393078 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.684812 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.821716 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.053397 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:33:57.971354; size=None; i=14; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=16/20, total=56/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:33:57.976659; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.943750 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.628210 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.876633 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.154969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.476918 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.610832 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.122201 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.148773 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.911173 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.507655 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:34:58.310794; size=None; i=15; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=17/20, total=57/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:34:58.316020; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.795985 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.600519 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.854235 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.425362 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.025798 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.969306 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.822085 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.059580 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.608620 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.035911 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:35:59.291156; size=None; i=16; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=18/20, total=58/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:35:59.295355; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.938198 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.721707 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.332480 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.662133 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.899280 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.878031 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.573011 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.625277 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.679965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.408754 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:37:01.907134; size=None; i=17; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=19/20, total=59/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:37:01.911454; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.894976 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.841397 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.364653 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.728983 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.964982 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.378480 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.056112 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.181523 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.638461 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.356666 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:38:04.182521; size=None; i=18; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=20/20, total=60/60, task=SparqlSyntaxFixingListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:38:04.186811; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.851119 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.642734 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.288001 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.762132 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.100096 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.364697 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.247551 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.050663 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.365582 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.202496 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 09:39:04.720350; size=None; i=19; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO] Total bytes transfered(in+out) per model: {}
[INFO] done, 2024-05-09 09:39:04.724717

real	60m6,961s
user	0m8,334s
sys	0m3,224s
Completed ModelGpt-SparqlSyntaxFixingListLcQuad-20x: Model - 1/1, Task - 1/1, Iteration - 3/1
2024-05-09T09:39:04+02:00 starting: ModelGpt-Text2SparqlExecEvalListLcQuad-20x
Do 9. Mai 09:39:04 CEST 2024
[INFO] benchmark configuration set: tasks:['Text2SparqlExecEvalListLcQuad']; iterations:20; sizes:[1000]; models:['GPT-3.5t16k_2024-01', 'GPT-4t_2023-11', 'GPT-4t_2024-04']
[INFO] Start for task 'Text2SparqlExecEvalListLcQuad' version '3.0' at 2024-05-09 09:39:06.729413. Task parameter: {}
[INFO]   model=GPT-gpt-3.5-turbo-0125 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=1/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:39:06.775746; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.978853 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.504446 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.864905 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.453258 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.727253 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.834530 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.494536 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.440799 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.383230 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.408861 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:40:10.022802; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=2/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:40:10.038524; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.767287 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.504965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.891744 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.648821 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.797920 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.791346 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.172794 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.501753 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.988986 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.834197 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:41:13.618785; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=3/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:41:13.625096; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.954758 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.609591 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.964046 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.657822 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.865032 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.492240 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.124072 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.895464 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.152167 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.297345 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:42:15.544287; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=4/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:42:15.548656; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.830633 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.667984 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.937686 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.678434 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.699294 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.237930 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.653224 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.567864 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.273731 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.026412 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:43:13.957429; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=5/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:43:13.963467; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.895171 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.951710 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.622139 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.925446 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.900425 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.067531 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.894468 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.313259 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.536476 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.355337 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:44:16.391437; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=6/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:44:16.394825; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.984678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.584080 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.976583 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.007535 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.617135 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.535775 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.713244 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.520181 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.121874 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.577947 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:45:17.985991; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=7/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:45:17.989716; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.939145 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.694230 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.969796 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.795678 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.451326 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.787735 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.371928 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.837924 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.535127 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.484305 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:46:18.740656; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=8/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:46:18.744226; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.937530 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.607236 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.297856 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.966965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.893065 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.680811 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.741815 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.413610 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.729403 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.144386 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:47:19.149635; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=9/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:47:19.154101; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.879937 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.835697 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.256421 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.996219 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.719680 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.856798 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.283429 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.235457 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.227422 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.444242 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:48:18.430282; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=10/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:48:18.436388; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.773391 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.679374 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.269745 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.668990 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.219723 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.784906 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.668096 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.832155 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.979305 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.120253 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:49:20.410757; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=11/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:49:20.415376; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.853821 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.807722 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.044212 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.836531 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.804356 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.201792 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.848641 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.858488 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.520590 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.505847 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:50:19.552078; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=12/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:50:19.555587; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.937487 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.678949 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.658017 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.527690 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.915384 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.969344 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.005850 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.140119 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.914955 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.982126 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:51:23.263068; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=13/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:51:23.270327; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.979311 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.653937 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.330019 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.719143 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.856198 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.012059 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.573178 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.408469 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.258446 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.506312 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:52:23.532543; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=14/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:52:23.537520; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.847852 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.912242 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.529702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.433324 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.554992 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.397428 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.701435 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.027065 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.401436 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.090968 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:53:21.515340; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=15/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:53:21.519829; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.865298 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.887954 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.087392 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.853778 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.096043 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.833397 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.243187 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.561007 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.329667 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.432950 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:54:19.763581; size=None; i=14; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=16/20, total=16/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:54:19.768834; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.927805 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.968884 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.595140 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.175030 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.823207 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.215900 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.188236 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.761935 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.997754 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.619303 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:55:17.965090; size=None; i=15; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=17/20, total=17/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:55:17.969870; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.817066 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.573973 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.421498 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.134752 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.337618 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.749688 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.177374 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.825614 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.228360 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.635221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:56:18.737945; size=None; i=16; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=18/20, total=18/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:56:18.742054; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.852345 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.625027 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.692513 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.939443 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.664566 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.167547 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.463357 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.592048 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.054897 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.006687 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:57:19.514153; size=None; i=17; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=19/20, total=19/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:57:19.519175; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.905899 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.804956 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.232539 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.952607 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.068042 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.107221 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.026108 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.912427 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.318989 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.016521 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:58:16.696514; size=None; i=18; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=20/20, total=20/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:58:16.700437; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.798124 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.825076 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.207729 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.530034 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.203119 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.828800 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.111512 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.557151 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.234629 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.054150 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-3.5t16k_2024-01--GPT-gpt-3.5-turbo-0125; time=2024-05-09 09:59:16.009251; size=None; i=19; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-1106-preview ...
[INFO]   size=None
[INFO]   iteration=1/20, total=21/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 09:59:16.061286; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.977730 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.714307 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.052922 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.743345 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.378812 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.698396 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.329727 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.558736 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.029238 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.402278 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:00:17.099522; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=22/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:00:17.103998; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.923323 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.887081 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.219411 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.033407 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.591392 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.913008 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.731835 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.086064 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.990815 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.695154 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:01:17.119075; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=23/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:01:17.123128; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.808103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.698927 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.044119 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.027824 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.517285 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.769110 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.464613 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.945037 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.350337 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.373554 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:02:15.832934; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=24/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:02:15.836389; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.776339 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.774545 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.087180 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.494605 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.266003 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.946482 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.132670 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.434515 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.428946 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.591599 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:03:16.475869; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=25/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:03:16.481016; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.964639 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.575944 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.448033 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.435215 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.224894 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.707295 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.706001 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.298753 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.685702 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.831957 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:04:14.185154; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=26/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:04:14.191047; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.899683 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.678180 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.760922 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.964035 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.380344 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.471677 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.022742 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.980421 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.948451 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.576153 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:05:12.496640; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=27/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:05:12.500912; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.911407 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.735145 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.760110 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.065039 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.856710 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.749841 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.985435 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.180227 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.747297 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.439645 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:06:13.830904; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=28/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:06:13.835217; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.848089 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.729461 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.647410 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.066136 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.864376 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.601464 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.837033 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.330744 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.120959 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.258792 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:07:14.178096; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=29/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:07:14.182014; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.891159 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.840353 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.214195 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.757439 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.458861 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.709554 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.216833 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.171095 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.386103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.090245 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:08:13.746970; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=30/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:08:13.752015; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.841542 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.660463 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.598997 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.563174 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.874048 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.867544 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.170853 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.877750 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.378647 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.230230 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:09:13.764659; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=31/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:09:13.769685; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.992545 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.810459 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.580015 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.788142 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.215023 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.359903 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.587914 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.050795 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.300769 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.363640 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:10:15.851408; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=32/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:10:15.856814; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.882145 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.924062 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.827013 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.621067 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.723965 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.504871 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.918275 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.690576 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.696311 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.073259 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:11:16.564141; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=33/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:11:16.569546; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.986439 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.816251 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.704451 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.393518 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.642487 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.717656 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.086428 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.516068 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.925357 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.195006 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:12:17.311984; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=34/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:12:17.315951; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.916292 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.991847 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.146140 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.137390 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.504046 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.812783 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.314595 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.816665 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.147047 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.385511 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:13:16.358082; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=35/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:13:16.364346; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.755846 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.576461 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.164284 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.888468 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.494986 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.591888 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.542961 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.895505 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.127387 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.314077 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:14:15.545853; size=None; i=14; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=16/20, total=36/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:14:15.550730; size=None; i=16
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.778964 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.671740 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.377776 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.618713 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.473618 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.263103 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.070957 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.670959 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.692639 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.266734 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:15:12.282786; size=None; i=15; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=17/20, total=37/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:15:12.287798; size=None; i=17
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.939991 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.805460 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.781860 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.019860 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.714326 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.550023 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.968364 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.387041 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.274642 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.100588 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:16:12.868689; size=None; i=16; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=18/20, total=38/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:16:12.874750; size=None; i=18
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.917402 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.829124 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.853166 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.849210 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.668102 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.960099 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.570993 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.375577 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.699718 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.347789 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:17:15.880145; size=None; i=17; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=19/20, total=39/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:17:15.885907; size=None; i=19
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.820253 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.718753 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.916780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.026828 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.940211 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.914540 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.476126 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.506102 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.540250 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.453523 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:18:17.998597; size=None; i=18; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=20/20, total=40/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:18:18.003253; size=None; i=20
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.965363 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.977588 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.099139 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.528731 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.754450 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.341215 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.634969 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.040067 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.876123 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.448389 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2023-11--GPT-gpt-4-1106-preview; time=2024-05-09 10:19:18.526705; size=None; i=19; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   model=GPT-gpt-4-turbo-2024-04-09 ...
[INFO]   size=None
[INFO]   iteration=1/20, total=41/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:19:18.572809; size=None; i=1
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.976915 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.887125 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.814126 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.070671 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.119096 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.295491 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.286079 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.620530 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.851548 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.924591 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:20:16.371719; size=None; i=0; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=2/20, total=42/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:20:16.379471; size=None; i=2
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.934123 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.936692 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.372697 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.494175 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.928417 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.547149 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.176719 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.765647 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.958012 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.547806 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:21:19.112312; size=None; i=1; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=3/20, total=43/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:21:19.118216; size=None; i=3
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.950474 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.798631 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.616768 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.186547 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.925418 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.691975 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.179660 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.052311 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.837967 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.853159 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:22:20.158628; size=None; i=2; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=4/20, total=44/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:22:20.162908; size=None; i=4
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.955315 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.831680 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.020242 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.822802 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.508454 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.505918 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.771085 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.024971 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.157492 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.616763 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:23:19.434948; size=None; i=3; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=5/20, total=45/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:23:19.440155; size=None; i=5
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.925194 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.837689 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.663621 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.220618 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.719968 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.409151 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.969498 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.658326 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.874424 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.912832 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:24:20.598545; size=None; i=4; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=6/20, total=46/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:24:20.604217; size=None; i=6
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.870586 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.907779 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.059856 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.060392 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.826761 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.147743 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.461568 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.174761 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.147854 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.171512 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:25:17.475730; size=None; i=5; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=7/20, total=47/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:25:17.480936; size=None; i=7
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.856092 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.840750 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.976658 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.015636 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.862176 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.091109 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.141790 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.112420 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.434211 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.398784 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:26:17.969686; size=None; i=6; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=8/20, total=48/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:26:17.975836; size=None; i=8
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.886264 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.573263 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.484558 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.554751 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.859048 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.225964 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.486212 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.785218 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.996957 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.667893 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:27:17.280366; size=None; i=7; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=9/20, total=49/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:27:17.285112; size=None; i=9
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.770897 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.523771 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.219420 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.214694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.317566 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.044707 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.479245 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.966157 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.329189 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.463468 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:28:15.354777; size=None; i=8; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=10/20, total=50/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:28:15.359419; size=None; i=10
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.802805 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.844014 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.988263 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.454488 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.189972 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.465123 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.137774 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.856275 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.932183 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.191074 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:29:16.972333; size=None; i=9; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=11/20, total=51/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:29:16.977721; size=None; i=11
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.893483 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.800485 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.462591 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.633207 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.927694 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.212503 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.988650 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.359382 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.281362 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.381656 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:30:17.761076; size=None; i=10; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=12/20, total=52/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:30:17.765549; size=None; i=12
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.867200 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.893780 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.117159 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.470437 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.626831 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.670778 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.006671 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.748369 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.773379 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.747035 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:31:20.538419; size=None; i=11; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=13/20, total=53/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:31:20.543734; size=None; i=13
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.800402 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.770133 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.310944 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.292930 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.255970 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.472174 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.234256 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.422455 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.479028 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.440744 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:32:18.066642; size=None; i=12; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=14/20, total=54/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:32:18.071791; size=None; i=14
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.961130 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.893276 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.061962 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.132152 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.551116 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.434264 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.417175 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.136380 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 7.730967 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.307488 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[ERROR] exception while evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:33:18.646737; size=None; i=13; exception=Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/run.py", line 305, in <module>
    result = taskInstance.evaluate_model(model, max_length=size, **moreEvalArgs)
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/task.py", line 429, in evaluate_model
    answer = model.generate_text(inputs=self.prompt) # TODO: check if max_length should be used here as well
  File "/mnt/d/git/LLM_KG_Bench/LlmKgBench/api/model.py", line 201, in generate_text
    answerObject = self.client.chat.completions.create(model=self.model, messages=messages)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_utils/_utils.py", line 275, in wrapper
    return func(*args, **kwargs)
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 663, in create
    return self._post(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1200, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 889, in request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 965, in _request
    return self._retry_request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1013, in _retry_request
    return self._request(
  File "/home/lpm/.cache/pypoetry/virtualenvs/llm-kg-bench-lM_Xw7Gx-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 980, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[INFO]   iteration=15/20, total=55/60, task=Text2SparqlExecEvalListLcQuad ...
[INFO]     evaluating model=GPT-4t_2024-04--GPT-gpt-4-turbo-2024-04-09; time=2024-05-09 10:33:18.653371; size=None; i=15
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 0.805510 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 1.845358 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 3.635870 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.099270 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.943486 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.678529 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.429913 seconds
[INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO] Retrying request to /chat/completions in 6.679265 seconds
